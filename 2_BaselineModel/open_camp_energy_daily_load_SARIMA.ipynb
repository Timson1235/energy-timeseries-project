{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time              from                to          load      residual  \\\n",
      "0  2018-11-01  01.11.2018 00:00  02.11.2018 00:00  55435.677083  41248.750000   \n",
      "1  2018-11-02  02.11.2018 00:00  03.11.2018 00:00  58741.354167  42638.614583   \n",
      "2  2018-11-03  03.11.2018 00:00  04.11.2018 00:00  52306.989583  43333.406250   \n",
      "3  2018-11-04  04.11.2018 00:00  05.11.2018 00:00  48647.406250  39556.520833   \n",
      "4  2018-11-05  05.11.2018 00:00  06.11.2018 00:00  60938.635417  50280.781250   \n",
      "\n",
      "        pumped  month  weekday  hour  \n",
      "0  1779.239583     11        3    23  \n",
      "1  1374.125000     11        4    23  \n",
      "2  1228.177083     11        5    23  \n",
      "3  1411.552083     11        6    23  \n",
      "4  1394.739583     11        0    23  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "\n",
    "# Agg backend for non-GUI rendering\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "# CSV file load\n",
    "file_path = r\"C:\\Users\\fanek\\Documents\\Open Campus Time Series\\DeepAR\\aggregated_daily_load.csv\"\n",
    "daily_df = pd.read_csv(file_path)\n",
    "print(daily_df.head())\n",
    "\n",
    "# We parse 'time' as datetime and an index\n",
    "daily_df['time'] = pd.to_datetime(daily_df['time'])\n",
    "\n",
    "daily_df.set_index('time', inplace=True)\n",
    "\n",
    "# Let's define the data for training and testing. We can always change the size of these, at our convenience.\n",
    "train_data = daily_df.loc['2020-01-01':'2020-10-31', 'load']\n",
    "test_data = daily_df.loc['2020-11-01':\"2020-12-31\", 'load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.6350773459199044\n",
      "p-value: 0.4648341630434809\n",
      "                                      SARIMAX Results                                      \n",
      "===========================================================================================\n",
      "Dep. Variable:                                   y   No. Observations:                  304\n",
      "Model:             SARIMAX(2, 1, 2)x(2, 1, [1], 7)   Log Likelihood                 -82.431\n",
      "Date:                             Mon, 09 Dec 2024   AIC                            180.862\n",
      "Time:                                     20:02:45   BIC                            210.385\n",
      "Sample:                                          0   HQIC                           192.682\n",
      "                                             - 304                                         \n",
      "Covariance Type:                               opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.5252      0.085      6.145      0.000       0.358       0.693\n",
      "ar.L2         -0.0438      0.066     -0.664      0.507      -0.173       0.086\n",
      "ma.L1         -1.8259      0.075    -24.214      0.000      -1.974      -1.678\n",
      "ma.L2          0.8402      0.073     11.443      0.000       0.696       0.984\n",
      "ar.S.L7        0.0175      0.082      0.213      0.831      -0.143       0.178\n",
      "ar.S.L14       0.0487      0.074      0.662      0.508      -0.095       0.193\n",
      "ma.S.L7       -0.9902      0.236     -4.196      0.000      -1.453      -0.528\n",
      "sigma2         0.0927      0.019      4.766      0.000       0.055       0.131\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.03   Jarque-Bera (JB):               768.89\n",
      "Prob(Q):                              0.87   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.25   Skew:                            -1.29\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        10.46\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fanek\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Stationary check using the ADF test\n",
    "result = adfuller(train_data)  # note that is achieved on the trained data\n",
    "print(f\"ADF Statistic: {result[0]}\")\n",
    "print(f\"p-value: {result[1]}\")\n",
    "\n",
    "# We are now going to scale the data sets to obtain a more stable outcome\n",
    "scaler = StandardScaler()\n",
    "scaled_train_data = scaler.fit_transform(train_data.values.reshape(-1, 1)).flatten()\n",
    "scaled_test_data = scaler.transform(test_data.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# If the ADF test is significant, this iff statement should go through\n",
    "if result[1] > 0.05:\n",
    "    train_data_diff = pd.Series(scaled_train_data).diff().dropna().values\n",
    "else:\n",
    "    train_data_diff = scaled_train_data\n",
    "\n",
    "# Define and fit the SARIMAX model\n",
    "mod = SARIMAX(train_data_diff, order=(2, 1, 2), seasonal_order=(2, 1, 1, 7))\n",
    "sarima_result = mod.fit(disp=False)\n",
    "\n",
    "# The model summary\n",
    "print(sarima_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step: forecasting the test data\n",
    "forecast = sarima_result.get_forecast(steps=len(scaled_test_data))\n",
    "forecast_index = test_data.index\n",
    "forecast_mean = forecast.predicted_mean\n",
    "forecast_conf_int = forecast.conf_int()\n",
    "\n",
    "# Again we rescale the results\n",
    "forecast_mean_rescaled = scaler.inverse_transform(forecast_mean.reshape(-1, 1)).flatten()\n",
    "test_rescaled = scaler.inverse_transform(scaled_test_data.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the forecasted vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_data.index, train_data, label='Training Data', color='blue')\n",
    "plt.plot(test_data.index, test_rescaled, label='Actual Test Data', color='orange')\n",
    "plt.plot(forecast_index, forecast_mean_rescaled, label='Forecasted Data', color='green', linestyle='--')\n",
    "plt.fill_between(\n",
    "    forecast_index,\n",
    "    scaler.inverse_transform(forecast_conf_int[:, 0].reshape(-1, 1)).flatten(),\n",
    "    scaler.inverse_transform(forecast_conf_int[:, 1].reshape(-1, 1)).flatten(),\n",
    "\n",
    "    color='pink',\n",
    "    alpha=0.3,\n",
    "    label='Confidence Interval'\n",
    ")\n",
    "plt.title('SARIMA Forecast vs Actual Test Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot\n",
    "plt.savefig('sarima_forecast_vs_actual.png')\n",
    "\n",
    "# Next Step: This step comes in to observe the heteroskedastic residual variance\n",
    "# Plot the residuals of the SARIMA model.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sarima_result.resid, label=\"Residuals\")\n",
    "plt.title(\"Residuals of SARIMA Model\")\n",
    "\n",
    "rolling_std = pd.Series(sarima_result.resid).rolling(window=30).std()\n",
    "\n",
    "# Plot the rolling standard deviation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rolling_std, label=\"Rolling Std Dev\", color=\"red\")\n",
    "plt.title(\"Rolling Standard Deviation of Residuals\")\n",
    "plt.legend()\n",
    "#plt.savefig('sarima_rolling_std_residuals.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
